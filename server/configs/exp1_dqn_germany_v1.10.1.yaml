exp:
  name: &exp_name exp1_dqn_germany_v1.10.1
env:
  name: WRCGLaneFixedSpeedEnv
  with_speed: &with_speed true
  num_concat_image: 1
  repeat_thres: 50
  reward_max_speed: 20
  reward_coef: 1
  stack_penalty: 1
  action_penalty: 0
  fps: 5
  gray_scale: False
  image_size: &image_size 288
  action_spaces: !!seq
    - 'w'
    - 'a'
    - 'd'
    - ''
  resize_size: !!seq
    - *image_size
    - *image_size
buffer:
  name: ReplayBuffer
  exp_name: *exp_name
  buffer_size: !!float 2e5
  state:
    image:
      dim: !!seq
        - 7236 # 201 * 18 * 2
      type: np.float32
    speed: # if with_speed is true in env
      dim: !!seq
        - 1
      type: np.uint8
  action:
    dim: 1
    type: np.uint8
  reward:
    dim: 1
    type: np.float32
  done:
    dim: 1
    type: np.bool_
policy:
  name: DQN
  action_head: &action_head 3
  wait_time: 600.0
  model:
    action_head: *action_head
    with_speed: *with_speed
    input_channel: 3
    norm:
      image: 255.
      speed: 100.
  training:
    name: *exp_name
    lr: !!float 7.3e-4
    batch_size: 256
    gamma: 0.99
    epsilon: 0.8
    epsilon_min: 0.1
    epsilon_steps: !!float 1.0e6
    warmup_steps: 20000
    max_episode_length: 1000
    update_interval: 100
    target_update_interval: 10
    save_interval: 100
    gradient_steps: 10
    reward_deque_length: 1000
  inference:
    checkpoint:
    repeat_thres: 3


