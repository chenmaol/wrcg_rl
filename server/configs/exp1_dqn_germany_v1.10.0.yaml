exp:
  name: &exp_name exp1_dqn_germany_v1.10.0
env:
  name: WRCGDiscreteEnv
  with_speed: &with_speed true
  repeat_thres: 20
  reward_max_speed: 40
  reward_coef: 1
  stack_penalty: 1
  action_penalty: 0
  fps: 5
  image_size: &image_size 224
  action_spaces: !!seq
    - 'w'
    - 'a'
    - 'd'
    - ''
  resize_size: !!seq
    - *image_size
    - *image_size
buffer:
  name: ReplayBuffer
  exp_name: *exp_name
  buffer_size: !!float 1.0e5
  state:
    image:
      dim: !!seq
        - 3 # equal to num_concat_image * (1 if gray_scale else 3)
        - *image_size
        - *image_size
      type: np.uint8
    speed: # if with_speed is true in env
      dim: !!seq
        - 1
      type: np.uint8
  action:
    dim: &action_head 4
    type: np.float32
  reward:
    dim: 1
    type: np.float32
  done:
    dim: 1
    type: np.bool_
policy:
  name: DQN
  action_head: *action_head
  wait_time: 600.0
  model:
    action_head: *action_head
    with_speed: *with_speed
    input_channel: 3
    norm:
      image: 255.
      speed: 100.
  training:
    name: *exp_name
    lr: !!float 7.3e-4
    batch_size: 256
    gamma: 0.99
    epsilon: 1.0
    epsilon_min: 0.1
    epsilon_steps: !!float 1.0e6
    warmup_steps: 5000
    max_episode_length: 1000
    update_interval: 300
    target_update_interval: 3000
    save_interval: 100
    gradient_steps: 10
    reward_deque_length: 1000
  inference:
    checkpoint:
    repeat_thres: 3


