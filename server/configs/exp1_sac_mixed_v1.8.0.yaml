exp:
  name: &exp_name exp1_sac_mixed_v1.8.0
env:
  name: WRCGContinuousEnv
  with_speed: &with_speed true
  num_concat_image: 1
  repeat_thres: 10
  reward_max_speed: 40
  reward_coef: 1
  stack_penalty: 1
  action_penalty: 0
  fps: 2
  gray_scale: False
  image_size: &image_size 224
  action_spaces: !!seq
    - 'w'
    - 'a'
    - 'd'
  resize_size: !!seq
    - *image_size
    - *image_size
buffer:
  name: ReplayBuffer
  exp_name: *exp_name
  buffer_size: !!float 3.0e5
  state:
    image:
      dim: !!seq
        - 3 # equal to num_concat_image * (1 if gray_scale else 3)
        - *image_size
        - *image_size
      type: np.uint8
    speed: # if with_speed is true in env
      dim: !!seq
        - 1
      type: np.uint8
  action:
    dim: &action_head 2
    type: np.float32
  reward:
    dim: 1
    type: np.float32
  done:
    dim: 1
    type: np.bool_
policy:
  name: SAC
  action_head: *action_head
  wait_time: 600.0
  model:
    action_head: *action_head
    with_speed: *with_speed
    input_channel: 3
    norm:
      image: 255.
      speed: 100.
  training:
    name: *exp_name
    lr: !!float 7.3e-4
    batch_size: 256
    gamma: 0.95
    warmup_steps: 20000
    max_episode_length: 1000
    update_interval: 300
    save_interval: 100
    gradient_steps: 50
    reward_deque_length: 1000
    tau: 0.02
  inference:
    checkpoint: sac_actor_16200_v1.8.0_mixed_offline.pt
    repeat_thres: 3


